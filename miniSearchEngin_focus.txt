

1. 网页的表示 ripepage.lib －－vector<MyPage>
	
	提取文本信息：title, url, content
	将每一篇进行格式化
    ____________________________________
   |                                    |
   |	<doc>                             |
   |	   <docid>1</docid>               |
   |	   <url>...</url>                 |
   |	   <title>...</title>             |
   |	   <content>...</content>         |
   |	</doc>                            |
   |  <doc>                             |
   |      ...                           |
   |	</doc>                            |
   |    ...                             |
   |____________________________________| 


	string txt = "<doc><docid>" + docid + 
							 "</docid><url>" + url+
							 "</url><title>" + title +
							 "</title><content>" + content +
	             "</content></doc>";

	std::ofstream ofs;
	ofs << txt;
	

   在创建网页库的过程中，就可以得到 offset.lib

  ofs.tellp();// offset
	txt.size();//length

   offset.lib中的内容为(每一行):  
    ____________________________
   |                            |
   |  docid --> offset  length  |  正向索引
   |____________________________|
	
	ifs.seek(offset, ifs.beg);
	ifs.read(buff, length);

2. 网页的去重，两种方法
    1) topK的方法(对网页分词，抽象出一个分词类，并去停用词)
    		vector<string> A;
    		vector<string> B;
    2) 通过寻找公共子序列 LCS
    		strA = "abc,bdc,helo,world";
    		strB = "xx,yy,zz,helo,world";

    词语 －〉词频   map<string, int>

    抽象出一个MyPage类,将所有的网页存入到一个vector<MyPage>里面去，

    通过去重之后，就可以得到一个新的new_offset.lib


    class MyPage
    {
    public:
	
    private:
        int docid_;
				string url_;
				string titile_;
				string content_;
				
				map<string, int>　wordFreMap_;
    };


3. 建立倒排索引表invertindex.lib

	std::map
	std::unordered_map
	__gnu__cxx::hash_map

	unordered_map<string, set<pair<int, double> > >;
    _________________________________________________________
   |                                                         |
   | word -> docid1 freq1 weight1, docid2 freq2 weight2, ... |
   |_________________________________________________________|
   
   	中国 : 1, 3, 10, 19, 31,32
   	hello :
   
   重点和难点就是weight的计算,要搞清楚几个概念：
   
   [tf-idf算法]
	 
	tf : term frequency, 某个词在文章中出现的次数
	df : document frequency, 某个词在所有文章中出现的次数(包含该词的文档数)
	idf: inverse document frequency, 逆文档频率，表示该词对于该篇文章的重要性的一个系数
		
		idf = log(N/df)          ---- N 表示文档的总数

	词的特征权重(该词对于该篇文章的重要性)的计算：
		w = tf * idf   

   然后要进行归一化处理：

	w' = w / sqrt(w1^2 + w2^2 +...+ wn^2)

	w' 才是我们真正需要存储下来的权重值weight

参考  http://www.ruanyifeng.com/blog/2013/03/tf-idf.html

＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝＝
4. 读取配置文件
   1) ripepage.lib路径
   2) offset.lib路径
   3) invertindex.lib路径
   4) 分词库路径
   5) 停用词库路径
   6) 服务器 IP, port


5. 余弦相似度的计算(查询到的网页进行排序)

   步骤：
   1) 对于查询的关键词，要把它们当作成一篇网页，计算出每个关键词的权重值

   2) 再通过倒排索引表invertindex.lib去寻找包含所有关键字的网页

   3) 对找到的网页进行排序--余弦相似度的计算
   
   							王道 在线 论坛
    查询词  X = [x1, x2, x3, ...]
	    Y = [y1, y2, y3, ...]
	    Z = [z1, z2, z3, ...]

	X * Y = (x1 * y1 + x2 * y2 + x3 * y3)

	|X| = sqrt(x1^2 + x2^2 + x3^2)
	|Y| = sqrt(y1^2 + y2^2 + y3^2)
	
	cos@ = (X * Y) / (|X| * |Y|)
	cos@ = (X * Z) / (|X| * |Z|)

   4) 将结果封装成json字符串发送到前端
   
   			 标题:
   			 　
   			 摘要：里面的内容是不固定的，根据查询词自动生成？
   			 
   			 URL:　　



    ->                                          i
王道  set_iterator[0] ->  (1  2  3  5  6  7  8)
    ->                                    j
在线  set_iterator[1] ->  (1  2  5  6  8  9)
    ->                                 k
论坛  set_iterator[2] ->  (1  3  6  8  10  11)

1  6   8

排序

set_iterator[3];
  

6. jsoncpp开源库---->学习其安装和使用

	http://www.cnblogs.com/kex1n/archive/2011/12/02/2272328.html
	
	
7. 源码
	https://github.com/haohb13/mini_search_engine

8. IO线程 vs 计算线程

EpollPoller所在的线程：IO线程  -- 与客户端的交互

Threadpool里面的线程: 计算线程 -- 进行任务的处理

IO线程与计算线程的通信   --  线程间的通信

文件描述符 -- Unix哲学:一切皆是文件
		sockfd/timerfd/eventfd  


进程间通信的方式：
		unix IPC:管道，命名管道FIFO，信号
		System V:共享内存，消息队列，信号量
						 socket